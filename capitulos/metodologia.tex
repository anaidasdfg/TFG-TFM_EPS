 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Plantilla TFG/TFM
% Escuela Politécnica Superior de la Universidad de Alicante
% Realizado por: Jose Manuel Requena Plens
% Contacto: info@jmrplens.com / Telegram:@jmrplens
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Metodología}
\label{metodologia}
\par El desarrollo de este \gls{tfg} va a consistir en la creación de un script de Python que tenga como entradas los datos de \gls{sar} de Sentinel-1, y como salida la función de densidad de probabilidad para la \gls{bbch} y/o altura de la planta, utilizando \gls{rfr} para realizar esta estimación. 
\\
\par Los datos de entrada de satélite de los que disponemos constan de las 7 parcelas de arroz sobre las que se trabaja: Calogne, Ermita, Puntal, Mínima, Puebla, Reboso y Vega, y los valores en dB del coeficiente de backscattering para polarizaciones VV y VH, obtenidos de las imágenes \gls{sar}, con periodo de revista de 6 días. Para realizar el modelo de observación necesitamos contrastar con datos reales de los cultivos utilizados, por lo que se dispone también de los siguientes datos de las 7 parcelas para los años 2017 y 2018: su posición geográfica, área, días de siembra y de cosecha, producción, \gls{bbch} total, mínima y máxima, la altura media del cultivo y los días del año para los cuales se han tomado estos datos. De todos ellos, los más relevantes para este estudio son la \gls{bbch} por parcela, la altura del cultivo y los días de siembra, cosecha y de toma de datos, los cuáles no tienen porqué coincidir con el periodo de revista de los satélites de Sentinel-1.
\\
\par  El procesamiento que los datos de satélite necesitan para la elaboración del modelo es distinto dependiendo del método utilizado. En este proyecto se realizan pruebas para la estimación de 3 casos de salidas distintas: \gls{bbch}, altura (cm) y \gls{bbch} junto a altura (cm). Además, cada uno de estos casos se evalúa utilizando los datos de entrada a nivel de parcela (mediante la media) y a nivel de pixel, desconociendo a priori qué método obtiene mejores resultados. Para ambos métodos, el procesamiento de los datos comienza restringiendo la información al periodo que nos interesa: desde el día de siembra hasta el de cosecha. A continuación, se ajustan los días de los que se tiene información realizando una interpolación para los datos de \gls{bbch} y/o altura, haciéndolos coincidir con las fechas de toma de datos del satélite, cuyos datos no deben interpolarse ya que su evolución no es tan creciente lineal como la altura o la fenología. El siguiente procesamiento se da únicamente para el método a nivel de parcela: se realiza la media y la desviación estándar de los datos que vamos a utilizar como entradas del sistema (VV en dB, VH en dB, y el ratio entre ambos, VH-VV, también en dB). Para finalizar la preparación de los datos, se dividen estos en sets de entrenamiento y de test. La división se realiza por parcelas completas, para que sea más sencillo y completo su entrenamiento y posterior visualización. Para todos los casos se reservan 6 parcelas de entrenamiento y 1 de test de resultados, seleccionando este número y las parcelas concretas que mejor entrenan el sistema y optimizan los resultados. Los datos reales con los que se va a entrenar y examinar el modelo se preparan con la interpolación mencionada anteriormente y la división de parcelas que sigue los mismos requisitos que los datos de satélite. La única adaptación extra que tienen estos datos se da en el caso de nivel de pixel: como no contamos con la información medida en tierra a ese nivel de \gls{bbch} ni de altura, los valores generales para cada parcela interpolados deben ser asignados a cada uno de los píxeles correspondientes de esa parcela, es decir, todos los píxeles tendrán el mismo valor de salida para una misma parcela y día. Una interpretación gráfica aproximada de este procesamiento se puede ver en la figura *INSERTAR CROQUIS*.
\\
\par Una vez procesados todos los datos y creados los sets de entrenamiento y test, estos datos pueden ser guardados y cargados para no repetir el procesamiento en futuras ocasiones. A continuación, la implementación del regresor, su entrenamiento y evaluación completa la creación del modelo de observación y este está listo para realizar predicciones. En la creación del modelo existen distintos parámetros modificables según la técnica de \gls{rfr} para optimizarlo acorde con las características del problema que se intenta resolver. El número de estimadores o número de árboles es uno de los principales parámetros, por defecto 100, el cual va representar el número de árboles de decisión de los que se va a componer el regresor. Mayor número de árboles implica una mayor complejidad y la posibilidad de generar soluciones más profundas y precisas, con el riesgo de hacer un sistema excesivamente complejo que tenga sobreajuste u overfitting en su entrenamiento y que tenga un costo computacional muy elevado sin realmente aportar mejoras significativas. Otros parámetros variables en la creación del regresor, ya dentro de los árboles de decisión, son la profundidad máxima (número máximo de nodos y niveles de cada árbol, por defecto nulo), el mínimo número de muestras para dividir un nodo interno (por defecto 2), el número mínimo de muestras para un nodo final (por defecto 1) o estado aleatorio inicial en la creación de los árboles de decisión (por defecto nulo), entre otros. Debido a las características de nuestro sistema, se mantienen los valores por defecto de todos los parámetros excepto el número de estimadores y el estado de aleatoriedad, parámetros que se destinan a la optimización del regresor ya que son los más influyentes en los resultados finales. 
\\
\par La optimización del número de estimadores se realiza ejecutando una prueba para todas las posibilidades entre los valores 1 y 1000 y escogiendo el valor mínimo de estimadores que presente un máximo local no puntual del error cuadrático, es decir, al que tiende de manera progresiva, y con una mejora considerable. La optimización del estado de aleatoriedad se realiza de la misma manera. Este último parámetro también garantiza una generación aleatoria similar para los mismos parámetros independientemente de las veces que se realicen las pruebas, esto es, la ``semilla'' de la que parte esta generación es la misma, por lo que se puede realizar una evaluación fiable de los resultados, ya que no van a depender de cómo se hayan generado inicialmente los árboles de decisión. 
\\
\par EVALUACIÖn DE ¡¡RESULTADOS!! (pdf) --> comparación con valores test&pred. comparación estaods fenológicos o alturas entre sí, mejor funcionamiento, etapas planas etc. R^2, RMSE. 